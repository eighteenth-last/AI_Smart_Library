# Tokenizer é›†æˆæ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¬¡æ›´æ–°é›†æˆäº† **jtokkit** åº“ï¼ˆJava ç‰ˆæœ¬çš„ tiktokenï¼‰ï¼Œç”¨äºç²¾ç¡®è®¡ç®— AI å¯¹è¯ä¸­è¾“å…¥å’Œè¾“å‡ºçš„ Token æ•°é‡ã€‚

---

## ğŸ¯ æ›´æ–°ç›®æ ‡

1. **ç²¾ç¡®è®¡ç®—**ï¼šä½¿ç”¨ä¸ OpenAI/DeepSeek ç›¸åŒçš„ Tokenizer è®¡ç®— Token
2. **å®æ—¶ç»Ÿè®¡**ï¼šæ¯æ¬¡ AI å¯¹è¯æ—¶è‡ªåŠ¨è®¡ç®—è¾“å…¥å’Œè¾“å‡º Token æ•°é‡
3. **å‡†ç¡®è®°å½•**ï¼šå°†ç²¾ç¡®çš„ Token æ•°é‡ä¿å­˜åˆ° `token_usage_stats` è¡¨

---

## ğŸ“¦ æ–°å¢ä¾èµ–

### pom.xml

```xml
<!-- jtokkit - Tokenizer for Token counting (like tiktoken) -->
<dependency>
    <groupId>com.knuddels</groupId>
    <artifactId>jtokkit</artifactId>
    <version>1.0.0</version>
</dependency>
```

**è¯´æ˜**ï¼š
- `jtokkit` æ˜¯ Java ç‰ˆæœ¬çš„ tiktokenï¼Œä¸ OpenAI API ä½¿ç”¨ç›¸åŒçš„åˆ†è¯ç®—æ³•
- æ”¯æŒå¤šç§ç¼–ç å™¨ï¼š`cl100k_base`ï¼ˆGPT-3.5/GPT-4/DeepSeekï¼‰ã€`p50k_base`ï¼ˆGPT-3ï¼‰ç­‰

---

## ğŸ› ï¸ æ ¸å¿ƒç»„ä»¶

### 1. TokenCountUtil å·¥å…·ç±»

**æ–‡ä»¶è·¯å¾„**ï¼š`src/main/java/com/library/common/utils/TokenCountUtil.java`

```java
@Slf4j
public class TokenCountUtil {
    
    // ä½¿ç”¨ cl100k_base ç¼–ç å™¨ï¼ˆDeepSeek/GPT-4 é€šç”¨ï¼‰
    private static final EncodingRegistry REGISTRY = Encodings.newDefaultEncodingRegistry();
    private static final Encoding ENCODING = REGISTRY.getEncoding(EncodingType.CL100K_BASE);
    
    /**
     * è®¡ç®—æ–‡æœ¬çš„ Token æ•°é‡
     */
    public static int countTokens(String text) {
        if (text == null || text.isEmpty()) {
            return 0;
        }
        
        try {
            return ENCODING.encode(text).size();
        } catch (Exception e) {
            log.error("Token è®¡æ•°å¤±è´¥: {}", e.getMessage());
            return estimateTokensByLength(text); // é™çº§æ–¹æ¡ˆ
        }
    }
    
    /**
     * æ‰¹é‡è®¡ç®—å¤šä¸ªæ–‡æœ¬çš„ Token æ€»æ•°
     */
    public static int countTokens(String... texts) {
        int totalTokens = 0;
        for (String text : texts) {
            totalTokens += countTokens(text);
        }
        return totalTokens;
    }
    
    /**
     * è®¡ç®—å¯¹è¯æ¶ˆæ¯çš„ Token æ•°é‡ï¼ˆè€ƒè™‘æ¶ˆæ¯æ ¼å¼ï¼‰
     */
    public static int countMessageTokens(String role, String content) {
        // æ¶ˆæ¯æ ¼å¼ä¼šå¢åŠ ä¸€äº›é¢å¤–çš„ Token
        int formatTokens = 4; // role, content, im_start, im_end
        int contentTokens = countTokens(content);
        return formatTokens + contentTokens;
    }
}
```

---

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: è®¡ç®—å•ä¸ªæ–‡æœ¬çš„ Token

```java
String text = "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´";
int tokens = TokenCountUtil.countTokens(text);

System.out.println("Token æ•°é‡: " + tokens); // è¾“å‡ºï¼šToken æ•°é‡: 8
```

### ç¤ºä¾‹ 2: è®¡ç®—å¤šä¸ªæ–‡æœ¬çš„ Token

```java
String question = "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´";
String context = "ã€Šä¸‰ä½“ã€‹æ˜¯åˆ˜æ…ˆæ¬£åˆ›ä½œçš„ç³»åˆ—é•¿ç¯‡ç§‘å¹»å°è¯´";
String prompt = String.format("çŸ¥è¯†åº“ï¼š%s\n\né—®é¢˜ï¼š%s", context, question);

int totalTokens = TokenCountUtil.countTokens(prompt);
System.out.println("æ€» Token: " + totalTokens);
```

### ç¤ºä¾‹ 3: æ‰¹é‡è®¡ç®—

```java
String text1 = "ä½ å¥½";
String text2 = "ä¸–ç•Œ";
String text3 = "Hello World";

int totalTokens = TokenCountUtil.countTokens(text1, text2, text3);
System.out.println("æ‰¹é‡ Token: " + totalTokens);
```

### ç¤ºä¾‹ 4: è®¡ç®—å¯¹è¯æ¶ˆæ¯ Token

```java
String role = "user";
String content = "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´";

int messageTokens = TokenCountUtil.countMessageTokens(role, content);
System.out.println("æ¶ˆæ¯ Token (å«æ ¼å¼): " + messageTokens);
```

---

## ğŸ”„ é›†æˆåˆ° AI å¯¹è¯æµç¨‹

### AiServiceImpl ä¿®æ”¹

#### 1. RAG æ¨¡å¼

```java
private void handleRagMode(String question, String sessionId, ChatResponseVO responseVO) {
    // æ„é€  RAG Prompt
    String ragPrompt = ragPromptTemplate.buildKnowledgeBasePrompt(question, searchResults);
    
    // âœ… è®¡ç®—è¾“å…¥ Token
    int inputTokens = TokenCountUtil.countTokens(ragPrompt);
    
    // è°ƒç”¨ DeepSeek ç”Ÿæˆ
    String answer = callDeepSeekChat(ragPrompt);
    
    // âœ… è®¡ç®—è¾“å‡º Token
    int outputTokens = TokenCountUtil.countTokens(answer);
    int totalTokens = inputTokens + outputTokens;
    
    // è®¾ç½® Token æ•°é‡
    responseVO.setInputTokens(inputTokens);
    responseVO.setOutputTokens(outputTokens);
    responseVO.setTotalTokens(totalTokens);
    
    log.info("RAG æ¨¡å¼ Token ç»Ÿè®¡ - è¾“å…¥: {}, è¾“å‡º: {}, æ€»è®¡: {}", 
            inputTokens, outputTokens, totalTokens);
}
```

#### 2. ä¼ ç»Ÿæ¨¡å¼

```java
private void handleTraditionalMode(String question, String sessionId, ChatResponseVO responseVO) {
    KnowledgeBase knowledgeBase = searchKnowledgeBase(question);
    
    if (knowledgeBase != null) {
        // çŸ¥è¯†åº“åŒ¹é…
        String answer = knowledgeBase.getAnswer();
        
        // âœ… è®¡ç®— Token
        int inputTokens = TokenCountUtil.countTokens(question);
        int outputTokens = TokenCountUtil.countTokens(answer);
        int totalTokens = inputTokens + outputTokens;
        
        responseVO.setInputTokens(inputTokens);
        responseVO.setOutputTokens(outputTokens);
        responseVO.setTotalTokens(totalTokens);
    } else {
        // DeepSeek API
        int inputTokens = TokenCountUtil.countTokens(question);
        String answer = callDeepSeekChat(question);
        int outputTokens = TokenCountUtil.countTokens(answer);
        
        responseVO.setInputTokens(inputTokens);
        responseVO.setOutputTokens(outputTokens);
        responseVO.setTotalTokens(inputTokens + outputTokens);
    }
}
```

---

## ğŸ“Š Token è®¡ç®—åŸç†

### 1. ç¼–ç å™¨ç±»å‹

| ç¼–ç å™¨ | é€‚ç”¨æ¨¡å‹ | Token ç‰¹ç‚¹ |
|--------|---------|-----------|
| `cl100k_base` | GPT-3.5, GPT-4, DeepSeek | æœ€æ–°çš„ç¼–ç å™¨ï¼Œæ”¯æŒå¤šè¯­è¨€ |
| `p50k_base` | GPT-3 (text-davinci-003) | æ—§ç‰ˆç¼–ç å™¨ |
| `r50k_base` | GPT-3 (text-davinci-002) | æ›´æ—§çš„ç¼–ç å™¨ |

**æœ¬é¡¹ç›®ä½¿ç”¨ `cl100k_base`**ï¼Œä¸ DeepSeek æ¨¡å‹ä¿æŒä¸€è‡´ã€‚

### 2. Token è®¡ç®—è§„åˆ™

#### ä¸­æ–‡æ–‡æœ¬
```
æ–‡æœ¬: "ä½ å¥½ï¼Œä¸–ç•Œï¼"
Token: çº¦ 7 ä¸ªï¼ˆå¹³å‡ 1.5 ä¸ªå­—ç¬¦ = 1 Tokenï¼‰
```

#### è‹±æ–‡æ–‡æœ¬
```
æ–‡æœ¬: "Hello, World!"
Token: çº¦ 4 ä¸ªï¼ˆå¹³å‡ 4 ä¸ªå­—ç¬¦ = 1 Tokenï¼‰
```

#### æ··åˆæ–‡æœ¬
```
æ–‡æœ¬: "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´ï¼Œæ¯”å¦‚ The Three-Body Problem"
Token: çº¦ 18 ä¸ª
```

### 3. æ¶ˆæ¯æ ¼å¼ Token

å¯¹äº OpenAI/DeepSeek çš„æ¶ˆæ¯æ ¼å¼ï¼š
```json
{
  "role": "user",
  "content": "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´"
}
```

å®é™… Token è®¡ç®—ï¼š
- **å†…å®¹ Token**: `countTokens(content)` â†’ 8
- **æ ¼å¼ Token**: 4ï¼ˆrole, content, im_start, im_endï¼‰
- **æ€» Token**: 8 + 4 = 12

---

## ğŸ§ª æµ‹è¯•æŒ‡å—

### è¿è¡Œå•å…ƒæµ‹è¯•

```bash
cd Server_Ai
mvn test -Dtest=TokenCountUtilTest
```

### æµ‹è¯•åœºæ™¯

#### 1. ä¸­æ–‡æ–‡æœ¬
```java
String text = "ä½ å¥½ï¼Œä¸–ç•Œï¼";
int tokens = TokenCountUtil.countTokens(text);
// é¢„æœŸï¼š6-8 ä¸ª Token
```

#### 2. è‹±æ–‡æ–‡æœ¬
```java
String text = "Hello, World!";
int tokens = TokenCountUtil.countTokens(text);
// é¢„æœŸï¼š3-4 ä¸ª Token
```

#### 3. é•¿æ–‡æœ¬
```java
String text = "ã€Šä¸‰ä½“ã€‹æ˜¯åˆ˜æ…ˆæ¬£åˆ›ä½œçš„ç³»åˆ—é•¿ç¯‡ç§‘å¹»å°è¯´...";
int tokens = TokenCountUtil.countTokens(text);
// é¢„æœŸï¼šå­—ç¬¦æ•°çš„ 60-70%
```

#### 4. RAG Prompt
```java
String prompt = "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼š\n\nçŸ¥è¯†åº“ï¼š...\n\né—®é¢˜ï¼š...";
int tokens = TokenCountUtil.countTokens(prompt);
// é¢„æœŸï¼šæ ¹æ®å®é™…å†…å®¹é•¿åº¦
```

---

## ğŸ“ˆ ç»Ÿè®¡ç¤ºä¾‹

### å¯¹è¯åœºæ™¯ 1: ç®€å•é—®ç­”

```
ç”¨æˆ·é—®é¢˜: "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´"
è¾“å…¥ Token: 8

AI å›ç­”: "æˆ‘æ¨èã€Šä¸‰ä½“ã€‹ï¼Œè¿™æ˜¯åˆ˜æ…ˆæ¬£åˆ›ä½œçš„ç§‘å¹»å·¨è‘—..."
è¾“å‡º Token: 45

æ€» Token: 53
```

### å¯¹è¯åœºæ™¯ 2: RAG å¢å¼º

```
åŸå§‹é—®é¢˜: "æ¨èä¸€æœ¬ç§‘å¹»å°è¯´"
çŸ¥è¯†åº“å†…å®¹: "ã€Šä¸‰ä½“ã€‹æ˜¯åˆ˜æ…ˆæ¬£åˆ›ä½œçš„ç³»åˆ—é•¿ç¯‡ç§‘å¹»å°è¯´ï¼Œè·å¾—é›¨æœå¥–..."
RAG Prompt: "æ ¹æ®ä»¥ä¸‹çŸ¥è¯†åº“å†…å®¹å›ç­”é—®é¢˜ï¼š\n\nçŸ¥è¯†åº“ï¼š...\n\né—®é¢˜ï¼š..."

è¾“å…¥ Token: 156ï¼ˆåŒ…å«çŸ¥è¯†åº“å†…å®¹ï¼‰
è¾“å‡º Token: 78
æ€» Token: 234
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. é™çº§ç­–ç•¥

å¦‚æœ Tokenizer è®¡ç®—å¤±è´¥ï¼Œä¼šè‡ªåŠ¨ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼š

```java
private static int estimateTokensByLength(String text) {
    // ä¸­æ–‡çº¦ 1.5 ä¸ªå­—ç¬¦ = 1 Token
    // è‹±æ–‡çº¦ 4 ä¸ªå­—ç¬¦ = 1 Token
    int chineseTokens = (int) Math.ceil(chineseCount / 1.5);
    int englishTokens = englishCount / 4;
    return chineseTokens + englishTokens;
}
```

### 2. æ€§èƒ½ä¼˜åŒ–

- **å•ä¾‹æ¨¡å¼**ï¼šEncoding å¯¹è±¡ä½¿ç”¨å•ä¾‹ï¼Œé¿å…é‡å¤åˆ›å»º
- **å¼‚å¸¸å¤„ç†**ï¼šè®¡ç®—å¤±è´¥æ—¶ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼Œä¸å½±å“ä¸»æµç¨‹
- **æ—¥å¿—è®°å½•**ï¼šè®¡ç®—å¤±è´¥æ—¶è®°å½•æ—¥å¿—ï¼Œä¾¿äºç›‘æ§

### 3. ç¼–ç å™¨é€‰æ‹©

å½“å‰ä½¿ç”¨ `cl100k_base`ï¼Œå¦‚æœéœ€è¦æ”¯æŒå…¶ä»–æ¨¡å‹ï¼š

```java
// GPT-3
Encoding encoding = REGISTRY.getEncoding(EncodingType.P50K_BASE);

// è‡ªå®šä¹‰ç¼–ç å™¨
Encoding encoding = REGISTRY.getEncodingForModel("gpt-4");
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£

- [jtokkit GitHub](https://github.com/knuddelsgmbh/jtokkit)
- [OpenAI Tokenizer](https://platform.openai.com/tokenizer)
- [tiktoken (Python)](https://github.com/openai/tiktoken)

### Token è®¡ç®—å·¥å…·

- **åœ¨çº¿å·¥å…·**: https://platform.openai.com/tokenizer
- **Python ç‰ˆæœ¬**: `pip install tiktoken`
- **Java ç‰ˆæœ¬**: jtokkitï¼ˆæœ¬é¡¹ç›®ä½¿ç”¨ï¼‰

---

## âœ… å®Œæˆæ¸…å•

- [x] æ·»åŠ  jtokkit ä¾èµ–
- [x] åˆ›å»º TokenCountUtil å·¥å…·ç±»
- [x] å®ç° Token è®¡ç®—æ–¹æ³•
- [x] é›†æˆåˆ° RAG æ¨¡å¼
- [x] é›†æˆåˆ°ä¼ ç»Ÿæ¨¡å¼
- [x] æ·»åŠ å•å…ƒæµ‹è¯•
- [x] ç¼–å†™ä½¿ç”¨æ–‡æ¡£
- [x] æ·»åŠ é™çº§ç­–ç•¥
- [x] è®°å½• Token ç»Ÿè®¡æ—¥å¿—

---

## ğŸ‰ ä¼˜åŠ¿å¯¹æ¯”

### ä¹‹å‰ï¼ˆä¼°ç®—æ–¹å¼ï¼‰
```
responseVO.setInputTokens(0);  // æ‰‹åŠ¨è®¾ç½®ä¸º 0
responseVO.setOutputTokens(0); // æ‰‹åŠ¨è®¾ç½®ä¸º 0
```
âŒ ä¸å‡†ç¡®  
âŒ æ— æ³•ç»Ÿè®¡çœŸå®æˆæœ¬  
âŒ æ— æ³•ä¼˜åŒ– Prompt

### ç°åœ¨ï¼ˆTokenizer æ–¹å¼ï¼‰
```
int inputTokens = TokenCountUtil.countTokens(prompt);   // ç²¾ç¡®è®¡ç®—
int outputTokens = TokenCountUtil.countTokens(answer);  // ç²¾ç¡®è®¡ç®—
```
âœ… **ç²¾ç¡®è®¡ç®—**ï¼šä¸ DeepSeek API ç›¸åŒçš„åˆ†è¯ç®—æ³•  
âœ… **çœŸå®ç»Ÿè®¡**ï¼šå‡†ç¡®è®°å½•æ¯æ¬¡å¯¹è¯çš„ Token æ¶ˆè€—  
âœ… **æˆæœ¬æ§åˆ¶**ï¼šåŸºäºçœŸå® Token è®¡ç®—æˆæœ¬  
âœ… **Prompt ä¼˜åŒ–**ï¼šæ ¹æ® Token æ•°é‡ä¼˜åŒ– Prompt é•¿åº¦

---

**æ›´æ–°æ—¶é—´**ï¼š2025-11-29  
**ä½œè€…**ï¼šAI Assistant  
**ç‰ˆæœ¬**ï¼š1.0.0
